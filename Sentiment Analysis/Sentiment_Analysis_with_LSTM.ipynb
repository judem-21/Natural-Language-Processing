{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXObLiuHlWbqWUMNwwN2Ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judem-21/Natural-Language-Processing/blob/main/Sentiment%20Analysis/Sentiment_Analysis_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SA Model"
      ],
      "metadata": {
        "id": "X52qYWWSiitB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY32_xoMVAPv",
        "outputId": "6870f7ac-a993-418d-96d8-b49cc165d79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m481.3/491.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from datasets import load_dataset\n",
        "from transformers import DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "WgnAFiKeXVk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"Sp1786/multiclass-sentiment-analysis-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "e801964bddf6423db4fc72f82f7c13af",
            "dff6ac7ef19c49c4b8b90a55075d9bc9",
            "4bc040c9612149fa888a082f9dd02e52",
            "f0b03b422ba74a72aa447db87b0a2113",
            "a4316dcfb86e4069bfb34f57564d6bfc",
            "4e479113f661402588e1f1efac7213a5",
            "76e063e353d04aefa5b19d35ef985de0",
            "00b3b752fbb147438688b137d218ae2d",
            "37e3ac521fa2422e976c4bc7375150a6",
            "51ad9de5f4be4e59aa16b0f8ab0a7264",
            "f551bb31b334481584fe3a5f5d4a64de",
            "05b408d5f8c941599018f5026170e97f",
            "b963e44f47a04c6b882140cd59d013a0",
            "16b250bd9e644068993b3a0671832b0b",
            "c42560dabe7b46fcaae0a57cfec3ed87",
            "143fb99e1c1b4f9a97f3c522fdfdbbf4",
            "ccad2834b9c245d085e87f5e39ca406d",
            "a555006570a2496d91d19339c0900929",
            "fb9a04add97346c3a11f61303bcb6974",
            "3d63cb543d5f447090a5b78a92d364f3",
            "068fcdb855cb404b8b953bf1f62b2d46",
            "387df5caa1fb41d0a43638f5e6ec5da4",
            "5c0dedf60c664c179247408e60838c92",
            "b072db5cac6a44ff912adabad3d1b979",
            "cf6a80a06ebc47f8983f2bd9759e05f4",
            "553fe95cc061419e9718b7369038cc1a",
            "9dcc6ed1ece048c58286fa7d51a1779a",
            "ffdd2e819d124198bfe25cc094f1fcd4",
            "5d56b7005fb64d1fb5307e1e165627c1",
            "1c0eb8409f3e410fac79583062f12190",
            "b4d20e1a1a0644c1a47196c2f8ecd067",
            "6ec8e7c78b1141cba2365e470f57495a",
            "f9124ee22b4944bdac0c4f3a79df910e",
            "874d776b07c74324822baa524376d3ee",
            "89fbe7c78642426a85865cc6c9d52689",
            "511eb1fbb40a4e39988f8afdd045ed42",
            "0197a5f94b5b4256aa172671849cbf36",
            "da3e933d82d14a959796def3c225d0a0",
            "88bc3706b20a408099d66b20fe2543c2",
            "bfb2d13d3eef4be6b2a1d6c57b38247f",
            "5b7dac672b404c50a2fa4cbbc9037a76",
            "e935655703764ed3a80dbb365444389d",
            "c3826fa5ed5e4c1d9030a501da5d41d9",
            "eabe682a02db4a448ca90269804e1bfb",
            "6b05986ee53440288874ddd411be9fff",
            "ba7298e98781424288245ffa8790fb77",
            "3f0159bb48524f6daf923e6eab0a3050",
            "f3e27d1c91304de2b31de375a9c3dc7e",
            "9f5bc60aa863429daad31ae15a3b37b7",
            "d22270c5cefa4ffeac13e0bae2ec29c3",
            "717fd51cf0b24377b2be28a1f2fdce5e",
            "632a14522d5c4008b5b46a5702f6e213",
            "9debd1612a484b859588be92ca9808f1",
            "0f74b3c391f64f8ba3a6f3f662a7783f",
            "6afd054c6d3342509b164cf795bc8b6b",
            "690eeb63a480446bb5a65789fcc08116",
            "fa816342d6e149d7b4b4caf5cc388182",
            "07bc89e0e28e4a07ad74bb0b35d5c0c3",
            "cc64fae4041949448a700eda2d1e46f7",
            "ccd036b089a84704aea1afe38d147559",
            "89483ba71c6b4c66926302ca2fc620eb",
            "bb5b6b4b46b145488b91beecd94e6b58",
            "a536582720344a28b63f39d30ff671ce",
            "5431a4c145b4449c9c65d7fab4833e1c",
            "b86e7728a43443b09e30d25647c8c96a",
            "5d58cadd833e47dfab08542ca960b6d3",
            "b9934fabc9d04df3a52dd63803dc668a",
            "f742758c95334fbcae15311b2c1b81f9",
            "c56a2bc7d5f04844bba113fe5d3eb141",
            "46b4029ca73b43bf9e80361afdb9d512",
            "99d04770dc8d4cb3b2f1885b9d1219d9",
            "dd080e9d58dd4e2fbe3f511833bc9123",
            "21026bbc38284edb8bbd01dc0ba22ab6",
            "539282ef4c784e71b36399447f7d668f",
            "13974a6b980245f59436d526149db12e",
            "2aa476ae7d414909a8e3864208d135a0",
            "a2dbe5a810254724ae16e903d874d42e"
          ]
        },
        "id": "00aCGwDBuzSR",
        "outputId": "3edb7146-3008-4da4-eeba-816cc1955e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e801964bddf6423db4fc72f82f7c13af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train_df.csv:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05b408d5f8c941599018f5026170e97f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "val_df.csv:   0%|          | 0.00/601k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c0dedf60c664c179247408e60838c92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test_df.csv:   0%|          | 0.00/586k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "874d776b07c74324822baa524376d3ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/31232 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b05986ee53440288874ddd411be9fff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/5205 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "690eeb63a480446bb5a65789fcc08116"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/5206 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9934fabc9d04df3a52dd63803dc668a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a45cdb931d5f459499a8b1561b079507",
            "d66eff5ad8f04a46a9e7500b02681c48",
            "7e4f3cf0181646108ef5640b91d15b1d",
            "949bccba7dc64e2d8e8b65fbd3cff217",
            "079ba26d03bd4f3d821a710ce502f98f",
            "39a53147827446e4b1bd46426fe38196",
            "a7d4ca759b3f475f87134beac4fbe874",
            "33c5657ab8bc498899f75fc570b4e002",
            "c8f44e8de439406aa9e45e79c2cdb2cf",
            "a0bb735f58384abc91b5e63d01cdfbde",
            "77f21ad3c90d403daa22104250e2fa3d",
            "4b5d5a46d41447b380620bf1f669456c",
            "e5ee2ef6de3743508b19fc19cb97aa8a",
            "1ecdcfa567164bb3938aee9e207ec553",
            "bdd1a31e95784bf1a4ba3bcf2c2d9640",
            "f93e384b3520474bab3d7754ad95526f",
            "4dc59a5451324441b42961bfa43a7692",
            "5b38066e20614a44b2ce9658b0c8196b",
            "94a4e8fec0bb42389c98c8371e56e82c",
            "3039dcab6c8f43c29cd1b0449d3314a2",
            "66023e41ccb046e9babeb957a307bb7d",
            "4d36a98be49c430b9c4d62d951831c58",
            "76d91a40ec2c4030aef1ca30924d7ba1",
            "3a5e459f4d904ec6ab894f6d3226f1ac",
            "5fc06b4fd08e485aaaee1c3579071163",
            "f91981ae883f474da0f56e47745d2cad",
            "068d83d30f5b4211a823c3a87781eddb",
            "4beab6fc04714fd791b634723f763560",
            "81becc14f12b4ba28efc848b745313a4",
            "2c84d3bdb5d54c4289024b50feb705b5",
            "96a2fedb3dca4d7fb83a7ad55b114431",
            "ae90a44bc1f1478b9f7cb6dc8d746eeb",
            "3509293f144c4dd89d057581d6bccea0",
            "f94fa4fd12074bddb79e76ce60637dae",
            "df987f57b5564b99a8f6b8bffd9c1ae7",
            "f8a906899734494799f5433ced9dca8a",
            "baf10d11f3494914a7497d7956917d0d",
            "5bb6053aabae45e4bcbc4db01b2fe698",
            "b852ec338c7f405a8bc019b6649f5f92",
            "b5d1359e83784206a068853918c06eb8",
            "f642cbe2403e49d88fa45a711a9cace8",
            "f12a2fdf4e4c4f698ef8527d66836677",
            "38129252e64b4ea99162e2587501d0d0",
            "1256d2ac6c2f4b9ba854bc657cf10bd8"
          ]
        },
        "id": "qGwoxfvYu0nE",
        "outputId": "82b9fc5b-3d87-487d-a2db-3fabada9799b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a45cdb931d5f459499a8b1561b079507"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5d5a46d41447b380620bf1f669456c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76d91a40ec2c4030aef1ca30924d7ba1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f94fa4fd12074bddb79e76ce60637dae"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBGP9qRiHgBH",
        "outputId": "a799b4a0-d57c-4ca4-b01f-bbe117f57d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 793, 'text': '  sad face.', 'label': 0, 'sentiment': 'negative'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_none(example):\n",
        "    return example[\"text\"] is not None\n",
        "\n",
        "dataset['test'] = dataset['test'].filter(filter_none)\n",
        "dataset['validation']=dataset['validation'].filter(filter_none)\n",
        "dataset['train']=dataset['train'].filter(filter_none)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ebe952ca7f4047d8a0744166fb94be6e",
            "fd6fd869a029451c85cca3b4cbdd39fb",
            "700009af665d43cb8976dfe98bb98ca3",
            "a935ba521ac5458381a44c747d55759d",
            "10e20d7523444fe0ad66a6e3c29f2f7a",
            "2dc2c870466144338d0b93961cbe2f02",
            "82fca815f4a14b41ab47c63494536a8d",
            "8b514d450b164d7b83e19f42e1018ba1",
            "60bc64da78a4426299eda168cba97655",
            "0e6b7a8fc3af4a388cfa7cc4bab919eb",
            "5fa10286ee454bb384723c04b2e914af",
            "8a257f6b52454f77b87b3fe0534e1e18",
            "b424c1df68f44950ab1650c90b028c66",
            "967595aff916497897f3a0e59a1738d6",
            "3ab1d40259fe4e9e9cc1850afa266c2a",
            "b1b03e1089ce4ff0a55081d146482483",
            "e486ca1087054b469a04a7df8fa190dd",
            "c59b61fb40f04eb4a1cad60c492c2545",
            "b4c9de87c31549378c5b23344f28c23b",
            "c119f08592ca4a4988d3a833b1a60fb0",
            "93f1e40f566c460cae92e783c4d13dad",
            "5c2a16a9f60c44e1bb83730be4ff06a3",
            "32c7442f6d594e60b385f6491c929649",
            "976f617c96b54701ad4ca08a2693df3e",
            "c925822b792e42fd9bc9b339771694c1",
            "2619fdd81f9d481abd8618779b4692a4",
            "ce96e8a3e793408db71df7e0ac048a0f",
            "36e1d2fa9cd34411b94143ddf43cd340",
            "3fd7e04b741f46738d35cf0661f815d1",
            "2d7ef62ed8e94676ba53550aa1c33f3b",
            "85776e7d58ff448b8c292c5d5655a01b",
            "f49b9e1830c14a43bde748e85211a336",
            "05970d3e7cd54e85951a96c3a6ce8d21"
          ]
        },
        "id": "9rAUosrDyRmw",
        "outputId": "01330588-a996-4e99-e592-61fc905174d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/5206 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebe952ca7f4047d8a0744166fb94be6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/5205 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a257f6b52454f77b87b3fe0534e1e18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/31232 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32c7442f6d594e60b385f6491c929649"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "    tokenised = tokenizer(text=batch[\"text\"], truncation=True)\n",
        "    tokenised[\"labels\"] = batch[\"label\"]\n",
        "    return tokenised\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['id', 'text', 'sentiment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "fb0101cce556405fabe22350b482dd30",
            "343ce06be4da47249637adcc32a2d8eb",
            "8b1e80cd17e84ce3815887ba1cb4652c",
            "b11747d0f27c45e8bda6c95fc3adf832",
            "b0e3e7376c6d43dda7b8048dda1a9c06",
            "70e345d4b50d49648809a8cb02a2d2f0",
            "ab8252ab1c8c43959a8d1b718f22afed",
            "d16d1f1de3034effab11c87f9d5b3650",
            "7873d24c72394408ba2a71c95090e78e",
            "870a797801814607a20d14e2d559a7a9",
            "26d976f855c94895b46a37ae45563f16",
            "315981a2f8cb4439900ef820517e8ae5",
            "04d7cd7284be4b37b95d603b5090a995",
            "079ff51be5bc442682d82af03014e3fa",
            "f85c427f915241ea9139d12979dfd291",
            "8934dfd3bd024dc1a9c19d5928a94994",
            "27250d083e774cdeaba97afdef405efe",
            "50e233b7fc0c47ba9b254bb5038f5c21",
            "b08540b6c46b438ba8a88ddc81bc5821",
            "e3515739d616467a92ca001e2447b21f",
            "5c2d76a9850e4517996f9ba830b5fc14",
            "abfc52e660614f9e89ec75560309bb53",
            "0e7c0274201c4be3ae8f9487bffc4ac5",
            "651c277cf95e47a987701cf046b7d7f6",
            "a9e06a50ee714960865f89608121ce32",
            "0110031bdde74441bcc2423655d45d98",
            "6ba23ba995704faa9e369712f0c7ce52",
            "52088f5231f14423a0fba38fb2d9722f",
            "6836e21c02ad440c930d75ed695a49dc",
            "acfc2337d1fc402eb391fbe972b729ca",
            "34f6bce87b394ffc89e3011a755d08e9",
            "a8885a18a2334b1cb479685476028eac",
            "c756bb8e1dc14e53b5e281632366dd5d"
          ]
        },
        "id": "S3AB76Bsu-Hp",
        "outputId": "17508b78-8be0-42df-ae8b-24fb4b5400e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/31232 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb0101cce556405fabe22350b482dd30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5205 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "315981a2f8cb4439900ef820517e8ae5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5205 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7c0274201c4be3ae8f9487bffc4ac5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
        "train_loader = DataLoader(\n",
        "    tokenized_dataset[\"train\"],\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "uWW3bxIexSqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    print({k: v.shape for k, v in batch.items()})  # Shows input_ids, attention_mask shapes\n",
        "    print(f'Input Ids:{batch[\"input_ids\"]}')\n",
        "    print(f'Attention Mask:{batch[\"attention_mask\"]}')\n",
        "    print(f'Labels:{batch[\"labels\"]}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3-n2PVpzJad",
        "outputId": "0a756b93-625d-40ef-ecc5-994714533c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': torch.Size([32, 119]), 'token_type_ids': torch.Size([32, 119]), 'attention_mask': torch.Size([32, 119]), 'labels': torch.Size([32])}\n",
            "Input Ids:tensor([[  101,  2748,  3531,  ...,     0,     0,     0],\n",
            "        [  101,  2919,  2154,  ...,     0,     0,     0],\n",
            "        [  101,  1045,  2097,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,  2074,  2893,  ...,     0,     0,     0],\n",
            "        [  101, 10166,  1010,  ...,     0,     0,     0],\n",
            "        [  101,  2123,  1036,  ...,     0,     0,     0]])\n",
            "Attention Mask:tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "Labels:tensor([1, 1, 1, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 1, 0, 2, 0, 0, 2,\n",
            "        0, 0, 2, 2, 2, 2, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalyser(nn.Module):\n",
        "  def __init__(self,embedding_dim,vocab_size,num_rec_layers,dropout,pad_idx,bidirectional=True):\n",
        "    super().__init__()\n",
        "    #self.embedding_dim=embedding_dim\n",
        "    self.embeddings=nn.Embedding(vocab_size,embedding_dim,padding_idx=pad_idx)\n",
        "    self.linear=nn.Linear(embedding_dim,3)\n",
        "    self.lstm=nn.LSTM(input_size=embedding_dim,num_layers=num_rec_layers,hidden_size=embedding_dim,bidirectional=bidirectional,batch_first=True,dropout=dropout)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self,input):\n",
        "    input_embeddings=self.embeddings(input)\n",
        "    _,(out,_)=self.lstm(input_embeddings)\n",
        "    #print(f'Out:{out.shape},and permute shape:{torch.mean(out.permute(1,0,2),dim=1).shape}')\n",
        "    out=self.linear(self.dropout(torch.mean(out.permute(1,0,2),dim=1)))\n",
        "    return self.relu(out)"
      ],
      "metadata": {
        "id": "uWzq13OU02aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VByMMy6-aGJZ",
        "outputId": "e2e1a8e3-2eaa-4f2d-8165-c26bd0473c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "checkpoint_path='/content/drive/MyDrive/SentimentAnalysis/checkpoint.pth'\n",
        "legend={0:'Negative',1:'Neutral',2:'Positive'}\n",
        "pad_idx = tokenizer.pad_token_id\n",
        "model=SentimentAnalyser(embedding_dim=512,vocab_size=tokenizer.vocab_size,num_rec_layers=2,\n",
        "dropout=0.1,pad_idx=pad_idx, bidirectional=True).to(device)\n",
        "checkpoint=torch.load(checkpoint_path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "softmax=nn.Softmax(dim=1)"
      ],
      "metadata": {
        "id": "6byQaQny9x5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs,lr=100,0.001\n",
        "# Learning rate scheduler: reduce LR by gamma every 'step_size' epochs\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # halve LR every 5 epochs\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "min_loss=checkpoint['min_loss']\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "GLNcmpo65gkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs,labels,training=False):\n",
        "  if not training: return (outputs==labels).sum()/len(labels)\n",
        "  return (softmax(outputs).argmax(dim=1)==labels).sum()/len(labels)"
      ],
      "metadata": {
        "id": "yssYGeGTbfh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_losses=[]\n",
        "model.train()\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  batch_losses=[]\n",
        "  for idx,batch in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    inputs=batch['input_ids'].to(device)\n",
        "    labels=batch['labels'].to(device)\n",
        "    logits=model(inputs)\n",
        "    loss=loss_fn(logits,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_losses.append(loss.item())\n",
        "    if (epoch==1 or epoch%10==0) and (idx+1)%100==0:\n",
        "      print(f'Epoch {epoch}, Batch {idx+1}, Batch Loss:{batch_losses[-1]:.8f} and accuracy:{accuracy(logits,labels,training=True)*100}%')\n",
        "  epoch_losses.append(np.mean(batch_losses))\n",
        "  scheduler.step()\n",
        "  if epoch==1 or epoch%10==0:\n",
        "    print(f'Epoch {epoch}, Learning Rate={scheduler.get_last_lr()[0]}')\n",
        "  print(f'Epoch {epoch}, Epoch Loss:{epoch_losses[-1]:.4f}')\n",
        "  if epoch_losses[-1]<min_loss:\n",
        "    min_loss=epoch_losses[-1]\n",
        "    checkpoint={'model_state_dict':model.state_dict(),'optimizer_state_dict':optimizer.state_dict(),'min_loss':epoch_losses[-1].item()}\n",
        "    torch.save(checkpoint,checkpoint_path)\n",
        "    print('Model saved!')\n",
        "  print()"
      ],
      "metadata": {
        "id": "dVIaLBjk6QBi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "5676c411-5557-4ee5-8134-193c87fe5c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 100, Batch Loss:0.00234770 and accuracy:100.0%\n",
            "Epoch 1, Batch 200, Batch Loss:0.00174750 and accuracy:100.0%\n",
            "Epoch 1, Batch 300, Batch Loss:0.01880415 and accuracy:100.0%\n",
            "Epoch 1, Batch 400, Batch Loss:0.00063757 and accuracy:100.0%\n",
            "Epoch 1, Batch 500, Batch Loss:0.00139569 and accuracy:100.0%\n",
            "Epoch 1, Batch 600, Batch Loss:0.04056843 and accuracy:96.875%\n",
            "Epoch 1, Batch 700, Batch Loss:0.00707080 and accuracy:100.0%\n",
            "Epoch 1, Batch 800, Batch Loss:0.00831299 and accuracy:100.0%\n",
            "Epoch 1, Batch 900, Batch Loss:0.02338232 and accuracy:100.0%\n",
            "Epoch 1, Learning Rate=0.001\n",
            "Epoch 1, Epoch Loss:0.0242\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-7bec201e51ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}, Batch {idx+1}, Batch Loss:{batch_losses[-1]:.8f} and accuracy:{accuracy(logits,labels,training=True)*100}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''checkpoint={'model_state_dict':model.state_dict(),'optimizer_state_dict':optimizer.state_dict(),'min_loss':epoch_losses[-1].item()}\n",
        "torch.save(checkpoint,'/content/drive/MyDrive/SentimentAnalysis/checkpoint.pth')'''\n",
        "#"
      ],
      "metadata": {
        "id": "zeJJYBceaI2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader=DataLoader(tokenized_dataset['test'],batch_size=32,collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "KlNo-Irxa1xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "for idx,batch in enumerate(test_loader):\n",
        "  if (idx+1)%10!=0:continue\n",
        "  with torch.no_grad():\n",
        "    logits=model(batch['input_ids'].to(device))\n",
        "    logits=softmax(logits).argmax(dim=1)\n",
        "    #print(f'Logits shape: {logits.shape}')\n",
        "    print(f\"Batch: {idx+1}, Accuracy: {accuracy(logits,batch['labels'].to(device))*100}%\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk5pWZG6a8zs",
        "outputId": "595aeb4e-7edf-4599-a6d6-2991c0b483e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 10, Accuracy: 65.625%\n",
            "\n",
            "Batch: 20, Accuracy: 62.5%\n",
            "\n",
            "Batch: 30, Accuracy: 68.75%\n",
            "\n",
            "Batch: 40, Accuracy: 71.875%\n",
            "\n",
            "Batch: 50, Accuracy: 59.375%\n",
            "\n",
            "Batch: 60, Accuracy: 65.625%\n",
            "\n",
            "Batch: 70, Accuracy: 65.625%\n",
            "\n",
            "Batch: 80, Accuracy: 71.875%\n",
            "\n",
            "Batch: 90, Accuracy: 59.375%\n",
            "\n",
            "Batch: 100, Accuracy: 62.5%\n",
            "\n",
            "Batch: 110, Accuracy: 65.625%\n",
            "\n",
            "Batch: 120, Accuracy: 65.625%\n",
            "\n",
            "Batch: 130, Accuracy: 68.75%\n",
            "\n",
            "Batch: 140, Accuracy: 65.625%\n",
            "\n",
            "Batch: 150, Accuracy: 68.75%\n",
            "\n",
            "Batch: 160, Accuracy: 56.25%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}